{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bea1ad72",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "ake the work we did in the lessons further:\n",
    "* What other types of models (i.e. different classifcation algorithms) could you use?\n",
    "\n",
    "* How do the models compare when trained on term frequency data alone, instead of TF-IDF values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "76e398ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2933bb58",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from env import user, password, host\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "def get_db_url(database, host=host, user=user, password=password):\n",
    "    return f'mysql+pymysql://{user}:{password}@{host}/{database}'\n",
    "\n",
    "url = get_db_url(\"spam_db\")\n",
    "sql = \"SELECT * FROM spam\"\n",
    "\n",
    "df = pd.read_sql(sql, url, index_col=\"id\")\n",
    "df.head()\n",
    "\n",
    "tfidf = TfidfVectorizer()\n",
    "x = tfidf.fit_transform(df.text)\n",
    "y = df.label\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, stratify=y, test_size=.2)\n",
    "\n",
    "train = pd.DataFrame(dict(actual=y_train))\n",
    "test = pd.DataFrame(dict(actual=y_test))\n",
    "\n",
    "lm = LogisticRegression().fit(x_train, y_train)\n",
    "\n",
    "train['predicted'] = lm.predict(x_train)\n",
    "test['predicted'] = lm.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "04c783fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 97.44%\n",
      "---\n",
      "Confusion Matrix\n",
      "actual      ham  spam\n",
      "predicted            \n",
      "ham        3857   112\n",
      "spam          2   486\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.97      1.00      0.99      3859\n",
      "        spam       1.00      0.81      0.90       598\n",
      "\n",
      "    accuracy                           0.97      4457\n",
      "   macro avg       0.98      0.91      0.94      4457\n",
      "weighted avg       0.98      0.97      0.97      4457\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy: {:.2%}'.format(accuracy_score(train.actual, train.predicted)))\n",
    "print('---')\n",
    "print('Confusion Matrix')\n",
    "print(pd.crosstab(train.predicted, train.actual))\n",
    "print('---')\n",
    "print(classification_report(train.actual, train.predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9368f5fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 96.41%\n",
      "---\n",
      "Confusion Matrix\n",
      "actual     ham  spam\n",
      "predicted           \n",
      "ham        966    40\n",
      "spam         0   109\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.96      1.00      0.98       966\n",
      "        spam       1.00      0.73      0.84       149\n",
      "\n",
      "    accuracy                           0.96      1115\n",
      "   macro avg       0.98      0.87      0.91      1115\n",
      "weighted avg       0.97      0.96      0.96      1115\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy: {:.2%}'.format(accuracy_score(test.actual, test.predicted)))\n",
    "print('---')\n",
    "print('Confusion Matrix')\n",
    "print(pd.crosstab(test.predicted, test.actual))\n",
    "print('---')\n",
    "print(classification_report(test.actual, test.predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9b74c45",
   "metadata": {},
   "source": [
    "### 1. What other types of models (i.e. different classifcation algorithms) could you use?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9c56063c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bffc68b",
   "metadata": {},
   "source": [
    "* Decision Tree - TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bb3b8721",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 98.27%\n",
      "---\n",
      "Confusion Matrix\n",
      "actual           ham  spam\n",
      "tree_predicted            \n",
      "ham             3859    77\n",
      "spam               0   521\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.98      1.00      0.99      3859\n",
      "        spam       1.00      0.87      0.93       598\n",
      "\n",
      "    accuracy                           0.98      4457\n",
      "   macro avg       0.99      0.94      0.96      4457\n",
      "weighted avg       0.98      0.98      0.98      4457\n",
      "\n",
      "----------------------------------------------\n",
      "Validate Accuracy: 97.22%\n",
      "---\n",
      "Confusion Matrix\n",
      "actual          ham  spam\n",
      "tree_predicted           \n",
      "ham             959    24\n",
      "spam              7   125\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.98      0.99      0.98       966\n",
      "        spam       0.95      0.84      0.89       149\n",
      "\n",
      "    accuracy                           0.97      1115\n",
      "   macro avg       0.96      0.92      0.94      1115\n",
      "weighted avg       0.97      0.97      0.97      1115\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train = pd.DataFrame(dict(actual=y_train))\n",
    "test = pd.DataFrame(dict(actual=y_test))\n",
    "\n",
    "\n",
    "tree = DecisionTreeClassifier(max_depth=10).fit(x_train, y_train)\n",
    "train['tree_predicted'] = tree.predict(x_train)\n",
    "test['tree_predicted'] = tree.predict(x_test)\n",
    "\n",
    "print('Accuracy: {:.2%}'.format(accuracy_score(train.actual, train.tree_predicted)))\n",
    "print('---')\n",
    "print('Confusion Matrix')\n",
    "print(pd.crosstab(train.tree_predicted, train.actual))\n",
    "print('---')\n",
    "print(classification_report(train.actual, train.tree_predicted))\n",
    "print('----------------------------------------------')\n",
    "print('Validate Accuracy: {:.2%}'.format(accuracy_score(test.actual, test.tree_predicted)))\n",
    "print('---')\n",
    "print('Confusion Matrix')\n",
    "print(pd.crosstab(test.tree_predicted, test.actual))\n",
    "print('---')\n",
    "print(classification_report(test.actual, test.tree_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39cb8d96",
   "metadata": {},
   "source": [
    "* Random Forest TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "23b1ebea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 97.91%\n",
      "---\n",
      "Confusion Matrix\n",
      "actual             ham  spam\n",
      "forest_predicted            \n",
      "ham               3859    93\n",
      "spam                 0   505\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.98      1.00      0.99      3859\n",
      "        spam       1.00      0.84      0.92       598\n",
      "\n",
      "    accuracy                           0.98      4457\n",
      "   macro avg       0.99      0.92      0.95      4457\n",
      "weighted avg       0.98      0.98      0.98      4457\n",
      "\n",
      "----------------------------------------------\n",
      "Validate Accuracy: 96.77%\n",
      "---\n",
      "Confusion Matrix\n",
      "actual            ham  spam\n",
      "forest_predicted           \n",
      "ham               966    36\n",
      "spam                0   113\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.96      1.00      0.98       966\n",
      "        spam       1.00      0.76      0.86       149\n",
      "\n",
      "    accuracy                           0.97      1115\n",
      "   macro avg       0.98      0.88      0.92      1115\n",
      "weighted avg       0.97      0.97      0.97      1115\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train = pd.DataFrame(dict(actual=y_train))\n",
    "test = pd.DataFrame(dict(actual=y_test))\n",
    "\n",
    "forest = RandomForestClassifier(max_depth = 28, random_state= 123).fit(x_train, y_train)\n",
    "\n",
    "train['forest_predicted'] = forest.predict(x_train)\n",
    "test['forest_predicted'] = forest.predict(x_test)\n",
    "\n",
    "print('Accuracy: {:.2%}'.format(accuracy_score(train.actual, train.forest_predicted)))\n",
    "print('---')\n",
    "print('Confusion Matrix')\n",
    "print(pd.crosstab(train.forest_predicted, train.actual))\n",
    "print('---')\n",
    "print(classification_report(train.actual, train.forest_predicted))\n",
    "print('----------------------------------------------')\n",
    "print('Validate Accuracy: {:.2%}'.format(accuracy_score(test.actual, test.forest_predicted)))\n",
    "print('---')\n",
    "print('Confusion Matrix')\n",
    "print(pd.crosstab(test.forest_predicted, test.actual))\n",
    "print('---')\n",
    "print(classification_report(test.actual, test.forest_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09b39315",
   "metadata": {},
   "source": [
    "### 2. How do the models compare when trained on term frequency data alone, instead of TF-IDF values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "960c91b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer()\n",
    "x1 = cv.fit_transform(df.text)\n",
    "y1 = df.label\n",
    "\n",
    "x_train1, x_test1, y_train1, y_test1 = train_test_split(x1, y1, stratify=y, test_size=.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1273c39a",
   "metadata": {},
   "source": [
    "* Decision Tress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9a4730b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 98.27%\n",
      "---\n",
      "Confusion Matrix\n",
      "actual           ham  spam\n",
      "tree_predicted            \n",
      "ham             3859    77\n",
      "spam               0   521\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.98      1.00      0.99      3859\n",
      "        spam       1.00      0.87      0.93       598\n",
      "\n",
      "    accuracy                           0.98      4457\n",
      "   macro avg       0.99      0.94      0.96      4457\n",
      "weighted avg       0.98      0.98      0.98      4457\n",
      "\n",
      "----------------------------------------------\n",
      "Validate Accuracy: 96.86%\n",
      "---\n",
      "Confusion Matrix\n",
      "actual          ham  spam\n",
      "tree_predicted           \n",
      "ham             951    20\n",
      "spam             15   129\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.98      0.98      0.98       966\n",
      "        spam       0.90      0.87      0.88       149\n",
      "\n",
      "    accuracy                           0.97      1115\n",
      "   macro avg       0.94      0.93      0.93      1115\n",
      "weighted avg       0.97      0.97      0.97      1115\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train1 = pd.DataFrame(dict(actual=y_train1))\n",
    "test1 = pd.DataFrame(dict(actual=y_test1))\n",
    "\n",
    "\n",
    "tree = DecisionTreeClassifier(max_depth=20).fit(x_train1, y_train1)\n",
    "train1['tree_predicted'] = tree.predict(x_train1)\n",
    "test1['tree_predicted'] = tree.predict(x_test1)\n",
    "\n",
    "print('Accuracy: {:.2%}'.format(accuracy_score(train.actual, train.tree_predicted)))\n",
    "print('---')\n",
    "print('Confusion Matrix')\n",
    "print(pd.crosstab(train.tree_predicted, train.actual))\n",
    "print('---')\n",
    "print(classification_report(train.actual, train.tree_predicted))\n",
    "print('----------------------------------------------')\n",
    "print('Validate Accuracy: {:.2%}'.format(accuracy_score(test1.actual, test1.tree_predicted)))\n",
    "print('---')\n",
    "print('Confusion Matrix')\n",
    "print(pd.crosstab(test1.tree_predicted, test1.actual))\n",
    "print('---')\n",
    "print(classification_report(test1.actual, test1.tree_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ca5a615",
   "metadata": {},
   "source": [
    "* results are very similar"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
